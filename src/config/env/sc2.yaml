# @package _global_

env_args:
  continuing_episode: False
  difficulty: "7"
  game_version: null
  map_name: "3m"
  move_amount: 2
  obs_all_health: True
  obs_instead_of_state: False
  obs_last_action: False
  obs_own_health: True
  obs_pathing_grid: False
  obs_terrain_height: False
  obs_timestep_number: False
  reward_death_value: 10
  reward_defeat: 0
  reward_negative_scale: 0.5
  reward_only_positive: True
  reward_scale: True
  reward_scale_rate: 20
  reward_sparse: False
  reward_win: 200
  replay_dir: ""
  replay_prefix: ""
  state_last_action: True
  state_timestep_number: False
  step_mul: 8
  seed: null
  heuristic_ai: False
  heuristic_rest: False
  debug: False

test_greedy: True
test_nepisode: 32
test_interval: 10000
log_interval: 1000
runner_log_interval: 1000
learner_log_interval: 1000
t_max: 2050000

save_model: True
save_model_intereval: 200000 


action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

runner: "episode"

buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "q_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

name: "qmix"
